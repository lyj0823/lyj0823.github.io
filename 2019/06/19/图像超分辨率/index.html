<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Kopieren',
      copy_success: 'Kopiert',
      copy_failure: 'Kopieren fehlgeschlagen'
    }
  };
</script>

  <meta name="description" content="#图像超分辨率综述  ##摘要 图像超分辨率有广泛应用，基于深度卷积网络的图像超分辨率是一个快速发展的领域。本文在三个传统数据集合三个近期引入的具有挑战性的数据集上进行超分辨率创建，比较超过30个state-of-the-art超分辨率网络。我们将现存的图像超分辨率方法分为9个类别包含线性，残差，多分支，循环，逐步增长，基于注意力和对抗设计。在网络复杂度，模型输入和输出，学习细节，损失类型和重要">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/2019/06/19/图像超分辨率/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="#图像超分辨率综述  ##摘要 图像超分辨率有广泛应用，基于深度卷积网络的图像超分辨率是一个快速发展的领域。本文在三个传统数据集合三个近期引入的具有挑战性的数据集上进行超分辨率创建，比较超过30个state-of-the-art超分辨率网络。我们将现存的图像超分辨率方法分为9个类别包含线性，残差，多分支，循环，逐步增长，基于注意力和对抗设计。在网络复杂度，模型输入和输出，学习细节，损失类型和重要">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-06-24T03:09:31.255Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description" content="#图像超分辨率综述  ##摘要 图像超分辨率有广泛应用，基于深度卷积网络的图像超分辨率是一个快速发展的领域。本文在三个传统数据集合三个近期引入的具有挑战性的数据集上进行超分辨率创建，比较超过30个state-of-the-art超分辨率网络。我们将现存的图像超分辨率方法分为9个类别包含线性，残差，多分支，循环，逐步增长，基于注意力和对抗设计。在网络复杂度，模型输入和输出，学习细节，损失类型和重要">





  
  
  <link rel="canonical" href="http://yoursite.com/2019/06/19/图像超分辨率/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title> | Hexo</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archiv</a>

  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/06/19/图像超分辨率/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="John Doe">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">

              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              

              
                
              

              <time title="Erstellt: 2019-06-19 09:19:38" itemprop="dateCreated datePublished" datetime="2019-06-19T09:19:38+08:00">2019-06-19</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Bearbeitet am</span>
                
                <time title="Geändert am: 2019-06-24 11:09:31" itemprop="dateModified" datetime="2019-06-24T11:09:31+08:00">2019-06-24</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <center>
#图像超分辨率综述
</center>
##摘要
图像超分辨率有广泛应用，基于深度卷积网络的图像超分辨率是一个快速发展的领域。本文在三个传统数据集合三个近期引入的具有挑战性的数据集上进行超分辨率创建，比较超过30个state-of-the-art超分辨率网络。我们将现存的图像超分辨率方法分为9个类别包含线性，残差，多分支，循环，逐步增长，基于注意力和对抗设计。在网络复杂度，模型输入和输出，学习细节，损失类型和重要的网络结构的区别。所进行的广泛评估显示，在过去几年中，随着模型复杂性和大规模数据集可用性的相应提高，准确性持续快速增长。
还可以观察到被确定为基准的开创性的方法已经被当前的竞争者大大超越。除了近些年取得的进步，我们确定许多现存方法的缺陷并且提供未来研究方向。
##简介
SR旨在给定稀疏细节的低分辨率图像恢复除具有更高视觉质量和细节的高分辨率图像。也可以叫做图像缩放，插值，上采样，放大。
##背景介绍
图像超分辨率模型和优化目标  
y=F(x,theta)--->x=F'(y,theat')

<p>由于图像降质过程非常复杂并且受到很多因素如噪声，压缩，模糊（散焦和运动）以及其他人为因素。因此，大多数研究者将降质过程建模为<br>y=(x<em>k)| + n<br>这里k是模糊核，</em>  是卷积，| 是下采样，n是高斯噪声<br>优化目标是最小化数据保真度</p>
<p>##SISR<br>SISR问题被使用不同的深度学习技巧研究。我们将现有方法分为9种类型如图1所示，我们将早期的和最简单的网络设计称为线性网络。</p>
<p>###3.1线性网络<br>线性网络有简单的结构，信息流只有单独的路径，没有任何跨层连接或多分支。在这些网络设计中，堆叠多层卷积网络，输入从前向后依次计算。不同结构的不同在于上采样操作在前面还是在后面。需要注意的是有些网络学习产生LR和HR的残差。</p>
<p>####3.1.1早上采样<br>早上采样设计首先将LR输入上采样到和HR相同大小，然后学习分层特征表示来产生输出。常用的上采样操作是双三次线性插值，计算量较大。SRCNN是这个结构中的开创性工作。<br>SRCNN:超分辨率SRCNN是使用卷积网络在图像超分辨率的第一次尝试。这个工作启发很多别的尝试。它有三层卷积和两层ReLU.<br>训练数据集通过从高分辨率图像中裁剪32* 32无重叠块生成。LR输入首先下采样然后使用双三次线性插值上采样到和输出相同分辨率。SRCNN是端到端训练，损失函数为MSE。<br>VDSR:不像SRCNN和FSRCNN使用浅层网络结构，VDSR基于深度卷积网络结构VGG-net，在所有网络层使用固定大小的卷积核3*3。为了解决收敛缓慢，他们提出两个有效策略。首先，通过学习HR和LR的差而不是直接产生HR图像。其次，梯度被约束在[-theta，+theta],这允许使用大学习率从而加速训练过程。这个工作证明更深的网络可以提供更好的细节并且学习更加泛化的表示，能够用于多尺度超分辨率。<br>DnCNN:学习高频信息差而不是潜在超分图像。网络结构只是堆叠卷积，BN和ReLU.<br>IRCNN ;</p>
<p>####3.1.2后上采样设计<br>在一开始进行上采样计算量大，因此采取后采样操作在低分辨率空间学习然后在接近输出时上采样。<br>FSRCNN:网络设计上使用4个卷积层和1个反卷积层。和SRCNN不同在于输入，激活函数使用PReLU,训练数据使用91张[34]和网上收集的100张，使用图像扩增如旋转，翻转，放缩增加19倍。<br>ESPCN :高效的亚像素卷积实现实时。  </p>
<p>###3.2残差网络.<br>和线性网络不同的是使用跨层连接防止梯度消失。</p>
<p>####3.2.1single-stage 残差网络<br>EDSR</p>
<center>
#Feedback Network for Image Super-Resolution
<center>
##摘要
反馈机制在SR方法中未得到充分利用。本文提出SRFBN

<p>##<a href="https://github.com/Paper99/SRFBN_CVPR19" target="_blank" rel="noopener">SRFBN:https://github.com/Paper99/SRFBN_CVPR19</a><br>测试部分<br>下载预训练模型放在./models  </p>
<pre><code>python test.py -opt options/test/test_SRFBN_x2_BI.json  
python test.py -opt options/test/test_SRFBN_x3_BI.json  
python test.py -opt options/test/test_SRFBN_x4_BI.json  
python test.py -opt options/test/test_SRFBN_x3_BD.json  
python test.py -opt options/test/test_SRFBN_x3_DN.json</code></pre><p>在主目录下test.py中执行主函数main()，先获取参数列表，调用options.options下的函数parse对参数解析，关键使用json对传入参数进行解析；<br>json.loads(json_str,object_pairs_hook=OrderedDict)<br>bject_pairs_hook 的传入参数是有序的键值对表，而 object_hook 是无序的dict。并且两个参数都给的话，object_pairs_hook 的优先级要更高。<br>os.environ 用于获得有关系统的各种信息<br>os.getcwd()  用于返回当前工作目录<br>isinstance</p>
<p>from collections  import OrderedDict</p>
<p>使用dict时，Key是无序的。在对dict做迭代时，我们无法确定Key的顺序。而如果要保持Key的顺序，可以用OrderedDict<br>注意，OrderedDict的Key会按照插入的顺序排列，不是Key本身排序：</p>
<p>根据传入的参数设置，创建测试数据集合，脚本在data/<strong>init</strong>下</p>
<p>solver 包含优化设置和模型导入部分</p>
<p>###训练部分<br>在solvers下<strong>init</strong>中初始化类SRSolver()对象，通过<br>solver.train_step()进行训练，主要是LR图像输入网络，产生输出，计算损失然后更新迭代，这里损失函数可以选择l1或者l2</p>
<p>下面看网络结构在networks/<strong>init</strong><br>在SRSolver对象初始化中，self.model=create_model(opt)</p>
<p>再调用define_net()，<br>在该函数中，实现多个网络结构如DBPN,SRFBN,RDN等，选择对应的网络结构，然后在对应文件中导入对应类如<br>from .srfbn import SRFBN<br>这里会传入输入通道参数，输出通道参数等，</p>
<p>网络前向传播过程：<br>def forward(self,x)<br>输入x,sefl._reset_state()<br>–》self.block.reset_state()返回True<br>self.block = FeedbackBlock()是反馈模块的对象</p>
<p>x减去均值，双线性上采样，调用卷积模块计算fin，进入FB模块，根据设置的steps,重复使用FB模块，每一个时间节点都会有输出，计算得到每一时刻的输出，再与标签坐损失，这就是为什么在SRSolver中计算损失时会有for sr in outputs,然后根据输出的损失，赋予不同时间节点权重（实际上是1），得到损失后，反向传播梯度更新。后面是将训练信息写入日志。然后是在验证集上对模型性能评估，最后保存模型。# coding:utf-8</p>
<p>#!/usr/bin/python3<br>import os, cv2, matplotlib<br>matplotlib.use(‘Agg’) # before import matplotlib.pyplot or pylab!<br>from pylab import * # import matplotlib &amp; numpy</p>
<h1 id="tp-Type-0-3-Fix-Scale-0-1-Noise-Scale-0-1"><a href="#tp-Type-0-3-Fix-Scale-0-1-Noise-Scale-0-1" class="headerlink" title="tp = [Type=0-3, Fix/Scale=0/1, Noise Scale=0-1]"></a>tp = [Type=0-3, Fix/Scale=0/1, Noise Scale=0-1]</h1><p>#####################################################################</p>
<h1 id="Create-Normalized-Curve"><a href="#Create-Normalized-Curve" class="headerlink" title="Create Normalized Curve:"></a>Create Normalized Curve:</h1><p>def Curve(tp, p, t): # normalized curve<br>    if type(tp)!=str: tp = “sps” # tp=tp[0]<br>    s1 = p[2] * np.sin((p[0]<em>t+p[1])</em>np.pi)<br>    s2 = p[5] * np.sin((p[3]<em>t+p[4])</em>np.pi)<br>    if “sps” in tp: return (s1 + s2)/(abs(p[2]) + abs(p[5]))<br>    if “sms” in tp: return (s1 * s2)/(abs(p[2]) * abs(p[5]))<br>    if len(p)&gt;=9: s3 = p[8] * np.sin((p[6]<em>t+p[7])</em>np.pi)<br>    if “sss” in tp: return (s1 + s2 + s3)/(abs(p[2])+abs(p[5])+abs(p[8]))</p>
<h1 id="Get-Random-linewidth-alpha-Pairs"><a href="#Get-Random-linewidth-alpha-Pairs" class="headerlink" title="Get Random [linewidth, alpha] Pairs:"></a>Get Random [linewidth, alpha] Pairs:</h1><p>def LwAl(tp, n=1, dx=180): # random [linewidth, alpha] pair<br>    wa = np.random.rand(2<em>n); f = tp[1]</em>(dx/180-1)+1 # scale ratio<br>    wa[::2] = [round(f<em>(1.1</em>i+2),2) for i in wa[::2]] # linewidth<br>    wa[1::2] = [round(0.4*i+0.2,2) for i in wa[1::2]] # alpha<br>    if tp[0]==3: wa[::2] = round(f,2); # linewidth for tp=3<br>    return wa # type: np.array</p>
<h1 id="Rotate-or-Affine-the-Curve"><a href="#Rotate-or-Affine-the-Curve" class="headerlink" title="Rotate or Affine the Curve:"></a>Rotate or Affine the Curve:</h1><p>def RoAf(t, y, ra=0, af=None): # rotate or affine the curve<br>    if type(ra)!=np.ndarray: # rotational angle -&gt; matrix<br>        ra *= np.pi; ra = np.array([[cos(ra),-sin(ra)],[sin(ra),cos(ra)]])<br>    if type(af)==np.ndarray: ra = ra.dot(af); # affine &amp; rotate<br>    y = ra.dot(np.array([t,y])) # rotate/affine the curve<br>    return y[0,:], y[1,:] # t’=y[0,:], y’=y[1,:]</p>
<h1 id="Draw-Curve-with-Annotation"><a href="#Draw-Curve-with-Annotation" class="headerlink" title="Draw Curve with Annotation:"></a>Draw Curve with Annotation:</h1><p>def DrawCu(tp, p=None, xi=0, dx=20, yo=0, A=1, ra=0, af=0, wa=[]): # draw curve<br>    if type(tp)!=list and type(tp)!=tuple: tp = [tp,0,0] # default<br>    tp, fs, no = tp # tp[0]=Type, tp[1]=Fix/Scale, tp[2]=Noise Scale<br>    if p==None or len(p)&lt;6: # default: random curve parameters<br>        p = [round(2<em>i,2) for i in np.random.rand(9)]; p[2]=p[5]=p[8]=1<br>    t = np.linspace(xi, xi+2<em>dx, round(2</em>dx</em>(np.random.rand()+1)), endpoint=True)<br>    no = no/5 * (1+(tp==3)) * (np.random.rand(len(t))-0.5) # noise<br>    y = A * (Curve(tp,p,t) + yo + no) # vertically scale + translate<br>    t,y = RoAf(t-(xi+dx), y, ra, af) # horizontally adjust -&gt; rotate/affine<br>    if len(wa)&lt;2: wa = LwAl([tp,fs], 1, dx); # get [linewidth,alpha] pair<br>    an = str(tp)+”: “+”, “.join([str(i) for i in p])+”-&gt;”+”, “.join([str(i) for i in wa])<br>    plot(t, y, color=”k”, lw=wa[0], alpha=wa[-1], label=an)<br>    return t, y, wa, p</p>
<p>#####################################################################</p>
<h1 id="Extract-sps-Cell-Parameters"><a href="#Extract-sps-Cell-Parameters" class="headerlink" title="Extract sps Cell Parameters:"></a>Extract sps Cell Parameters:</h1><p>def Paras(tp, dx, A, f): # Extract sps Cell Parameters<br>    tp, yf = tp[0], tp[1]<em>(dx/180-1)+1 # Cell scale ratio<br>    if tp==0: # Reticulate Pattern Type0<br>        A = 42</em>yf; f = 12/dx; p = [0.2<em>f, 3/8, 0.5, 0.8</em>f, 0, 0.8]<br>    elif tp==1: # Reticulate Pattern Type1<br>        A = 30<em>yf; f = 8/dx; p = [0.2</em>f, 3/8, 0.5, 0.8<em>f, 0, 0.75]<br>    elif tp==2: # Reticulate Pattern Type2<br>        A = 55</em>yf; f = 8/dx; p = [0.2<em>f, 3/8, 0.5, 0.8</em>f, 0, 0.8]<br>        f = np.array([[1,-0.5],[-0.15,1]]); # Affine Matrix<br>    elif tp==3: # Reticulate Pattern Type3<br>        A = 10<em>yf; f = 7.5/dx; p = [0.2</em>f, 3/8, 0.5, 0.8<em>f, 0, 0.8]<br>        f = np.array([[1.15,1.1],[-0.45,0.7]]); # Affine Matrix<br>    else: A *= yf; f /= dx; p = [0.2</em>f, 3/8, 0.5, 0.8*f, 0, 0.8-tp%2/10]<br>    return A, p, f</p>
<h1 id="Draw-Reticulate-Pattern-Cell-sps"><a href="#Draw-Reticulate-Pattern-Cell-sps" class="headerlink" title="Draw Reticulate Pattern Cell(sps):"></a>Draw Reticulate Pattern Cell(sps):</h1><p>def DrawCell(tp, dx, yi=0, ra=0, wa=[], A=42, f=12): # draw sps cell<br>    xi = round(dx*np.random.rand(), 1)<br>    dy = round(0.2+(np.random.rand()-0.5)/10, 3)<br>    A,p1,f = Paras(tp,dx,A,f); # get sps Cell Parameters<br>    p2 = p1.copy(); p2[::-3] = [-i for i in p2[::-3]]<br>    # DrawCu set alpha=wa[-1], thus Curve Cells have same alpha:<br>    t1,y1,w1,p1 = DrawCu(tp, p1, xi, dx, yi+dy, A, ra, f, wa=wa[:])<br>    t2,y2,w2,p2 = DrawCu(tp, p2, xi, dx, yi-dy, A, ra, f, wa=wa[2:])<br>    return [t1,y1, t2,y2]</p>
<h1 id="Save-Mesh-Image-with-Mask"><a href="#Save-Mesh-Image-with-Mask" class="headerlink" title="Save Mesh Image with Mask:"></a>Save Mesh Image with Mask:</h1><p>def SaveIm(im, out, tp, qt=20, ms=None, ro=None, wa=None, gap=1.6):<br>    if type(im)==str: im = imread(im) # load image<br>    n = im.shape; y,x = n[0],n[1]; n = y//20 # width &amp; height<br>    if ro==None: ro = 2<em>np.random.rand()-1 # randomly rotate<br>    if wa==None or len(wa)&lt;4: wa = LwAl(tp,2,x) # [lw,alpha]<br>    ofs = round(1.5<em>np.random.rand(), 2)<br>    gap = round(gap+(np.random.rand()-0.3)/10, 2); net = []<br>    dpi = 72; figure(figsize=(x/dpi, y/dpi), dpi=dpi); axis(“off”)<br>    subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0, wspace=0)<br>    for i in range(2</em>n): net += DrawCell(tp, x, gap</em>(i-n)+ofs, ro, wa=wa)<br>    if ms != None: # output mask image<br>        xlim(-x/2,x/2); ylim(-y/2,y/2); ms = out[:-4]+”_m.png”<br>        savefig(ms, facecolor=”w”, dpi=dpi); tmp = cv2.imread(ms, 0)<br>        gap,tmp = cv2.threshold(tmp, 250, 255, cv2.THRESH_BINARY_INV)<br>        cv2.imwrite(ms, tmp, [int(cv2.IMWRITE_PXM_BINARY), 1])<br>    imshow(im, extent=(-x/2,x/2,-y/2,y/2)); savefig(out, dpi=dpi)<br>    if type(qt)!=int: qt = np.random.randint(qt[0],qt[1]) # quality<br>    cv2.imwrite(out, cv2.imread(out), [cv2.IMWRITE_JPEG_QUALITY, qt])<br>    close(“all”); return net</p>
<p>#####################################################################</p>
<h1 id="Crop-Randomly-OR-Resize-Image"><a href="#Crop-Randomly-OR-Resize-Image" class="headerlink" title="Crop Randomly OR Resize Image:"></a>Crop Randomly OR Resize Image:</h1><p>def Crop(im, size, op=”cut”): # size=(height,width), op=crop/resize<br>    if type(im)==str: im = cv2.imread(im) # OR: pylab.imread(im)<br>    if type(size)!=np.ndarray: size = np.array(size) # (height,width)<br>    imsz = np.array([im.shape[0],im.shape[1]]) # (height,width,depth)<br>    if (“c” in op) and (imsz&gt;=size).all(): # True only if all elements are Ture<br>        xy = np.array([np.random.randint(i) for i in imsz-size+1]); br = xy+size<br>        return im[xy[0]:br[0], xy[1]:br[1]] # randomly crop/cut<br>    else: return cv2.resize(im, (size[1],size[0]), interpolation=cv2.INTER_AREA)</p>
<h1 id="Batch-Adding-Meshes-to-Images-and-Saving"><a href="#Batch-Adding-Meshes-to-Images-and-Saving" class="headerlink" title="Batch Adding Meshes to Images and Saving:"></a>Batch Adding Meshes to Images and Saving:</h1><p>def BatchSave(src, tp, qt=20, num=None, ms=None):<br>    tp, fs, no = tp # parse: Type,Fix/Scale,Noise<br>    if type(tp)==int: tp = [tp] # tp=range/list/tuple<br>    N = len(tp); SZ = (220,178) # default (height,width)<br>    if num==None or type(num)!=int: num = N # default=N<br>    id = [i%N for i in range(num)] # default index of tp<br>    scr = os.path.abspath(src); ss = os.path.split(src)[-1]<br>    dst = ss + “<em>“.join([str(i) for i in [“”,fs,no]]) # target<br>    out = lambda im,k=””: im.replace(ss,dst)[:-4]+”</em>“+str(k)+”.jpg”<br>    for path,sub,file in os.walk(src): # traverse src<br>        os.mkdir(path.replace(ss,dst)); os.chdir(path) # cd path<br>        for im in file: # loop images in path<br>            im = os.path.join(path, im) # uesd in out()<br>            if num&lt;N: id = np.random.choice(N, num, False) # non-repetitive<br>            for i in range(num): SaveIm(im, out(im,i), (tp[id[i]],fs,no), qt, ms)<br>            # Crop/Resize Images-&gt;Save-&gt;Add Meshes to res/out(im):<br>            #res = Crop(imread(im), SZ, “cut”) # try: cv2.imread or “resize”<br>            #cv2.imwrite(out(im), res[:,:,::-1], [cv2.IMWRITE_JPEG_QUALITY, 95])<br>            #for i in range(num): SaveIm(res, out(im,i), (tp[id[i]],fs,no), qt, ms)<br>    os.chdir(os.path.join(src,”..”)) # cd parent directory</p>
<p>#####################################################################<br>if <strong>name</strong> == “<strong>main</strong>“:<br>    src = “E:/Hua/PyCharm/Test”<br>    #src = “/home/hua.fu/CASIA-WebFace/“<br>    tp = [range(4), 1, 0.3]<br>    BatchSave(src, tp, qt=95, num=3, ms=None)</p>
<center>
#SRGAN
</center>
##摘要
更快，更深的卷积网络在SR中取得效果，但是如何恢复更好的纹理细节仍待研究。基于优化的SR由目标函数驱动。近来工作大部分最小化MSE，其结果是很高的PSNR却导致缺乏高频信息，并且和人感知不符合，本文提出SRGAN首次推断4倍上采样，并且结果符合真实图像。为了实现这个目标，本文提出感知损失函数包含对抗损失和内容损失。判别器使得生成图像更加真实，内容损失在感知相似性中进行而不是在像素空间。我们的深度残差网络能够恢复除真实纹理，在benchmark中取得很好结果。

<p>将GAN应用于SR，旨在解决MSE过于平滑的超分辨率结果，恢复细节。<br>损失函数上使用基于特征的内容损失代替基于像素的MSE，并且使用对抗损失促使生成器生成结果更加符合真实图像</p>
<p>#EDSR训练4倍超分时使用2倍超分参数初始化模型，可以加快模型收敛</p>
</center></center>
      
    </div>

    

    
      
    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/07/26/hello-world/" rel="prev" title="Hello World">
                Hello World <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">Artikel</span>
        </a>
      </div>
    

    

    
  </nav>













          
          
        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#tp-Type-0-3-Fix-Scale-0-1-Noise-Scale-0-1"><span class="nav-number">1.</span> <span class="nav-text">tp = [Type=0-3, Fix/Scale=0/1, Noise Scale=0-1]</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Create-Normalized-Curve"><span class="nav-number">2.</span> <span class="nav-text">Create Normalized Curve:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Get-Random-linewidth-alpha-Pairs"><span class="nav-number">3.</span> <span class="nav-text">Get Random [linewidth, alpha] Pairs:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Rotate-or-Affine-the-Curve"><span class="nav-number">4.</span> <span class="nav-text">Rotate or Affine the Curve:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Draw-Curve-with-Annotation"><span class="nav-number">5.</span> <span class="nav-text">Draw Curve with Annotation:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Extract-sps-Cell-Parameters"><span class="nav-number">6.</span> <span class="nav-text">Extract sps Cell Parameters:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Draw-Reticulate-Pattern-Cell-sps"><span class="nav-number">7.</span> <span class="nav-text">Draw Reticulate Pattern Cell(sps):</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Save-Mesh-Image-with-Mask"><span class="nav-number">8.</span> <span class="nav-text">Save Mesh Image with Mask:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Crop-Randomly-OR-Resize-Image"><span class="nav-number">9.</span> <span class="nav-text">Crop Randomly OR Resize Image:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Batch-Adding-Meshes-to-Images-and-Saving"><span class="nav-number">10.</span> <span class="nav-text">Batch Adding Meshes to Images and Saving:</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Design – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/schemes/muse.js?v=7.2.0"></script>



  
  <script src="/js/scrollspy.js?v=7.2.0"></script>
<script src="/js/post-details.js?v=7.2.0"></script>



  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  










  





















<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>








  

</body>
</html>
